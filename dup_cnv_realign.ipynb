{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "063ba889-7e02-4d63-84b6-4158f6e2b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnv_realign - using detected cnv areas, realign cram file using jump aligner around cnv edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b549c0c-9271-49cb-ba29-771e5bbb7f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/drorkessler/miniconda3/lib/python3.10/site-packages/ipykernel_launcher.py', '-f', '/Users/drorkessler/Library/Jupyter/runtime/kernel-cd5db4ca-0a4d-4618-90f3-67636a334b1e.json']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/drorkessler/tmp/data/jump_align/251112/dups_small.bed'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# argumennt processing + debug environment files\n",
    "import sys\n",
    "import os\n",
    "\n",
    "MODE=\"DUP\"\n",
    "MATCH_SCORE = 2\n",
    "MISMATCH_SCORE = -8\n",
    "OPEN_SCORE = -18\n",
    "EXTEND_SCORE = -1\n",
    "JUMP_SCORE = 0\n",
    "\n",
    "MIN_MISMATCHES = 30\n",
    "SOFTCLIP_THRESHOLD = 30\n",
    "FETCH_READ_PADDING = 500\n",
    "FETCH_REF_PADDING = 0\n",
    "MIN_SEQ_LEN_JUMP_ALIGN_COMPONENT = 30\n",
    "MIN_GAP_LEN = 30\n",
    "MAX_READS_PER_CNV = 4000\n",
    "\n",
    "GCLOUD_AUTH = False\n",
    "INPUT_NAME_FULL = False\n",
    "\n",
    "print(sys.argv)\n",
    "tmp = \"/tmp/jump_align_input.\" + str(os.getpid())\n",
    "JUMP_ALIGN_CMD = [\"jump_align\", str(MATCH_SCORE), str(MISMATCH_SCORE), str(OPEN_SCORE), str(EXTEND_SCORE), \"-1\", str(JUMP_SCORE), tmp]\n",
    "JUMP_ALIGN_CMD2 = [\"para_jalign\", str(MATCH_SCORE), str(MISMATCH_SCORE), str(OPEN_SCORE), str(EXTEND_SCORE), \"-1\", str(JUMP_SCORE), tmp]\n",
    "\n",
    "if \"dup_cnv_realign\" in sys.argv[0] or \"stdin\" in sys.argv[0]:\n",
    "    if len(sys.argv) < 5:\n",
    "        print(\"usage: \" + sys.argv[0] + \" <input-cram> <range-bed> <ref-fasta> <output-prefix> [<mode>] [<min-mismatches]\\n\")\n",
    "        sys.exit(-1)\n",
    "    # commandline invocation\n",
    "    IN_CRAM = sys.argv[1]\n",
    "    CNV_BED = sys.argv[2]\n",
    "    REF_FASTA = sys.argv[3]\n",
    "    OUT_SAM = sys.argv[4] + \".sam\"\n",
    "    if len(sys.argv) >= 6:\n",
    "        MODE = sys.argv[5]\n",
    "    if len(sys.argv) >= 7:\n",
    "        MIN_MISMATCHES = int(sys.argv[6])\n",
    "    if len(sys.argv) >= 8:\n",
    "        FETCH_READ_PADDING = int(sys.argv[7])\n",
    "else:\n",
    "    \n",
    "    REF_FASTA = os.path.expanduser(\"~/tmp/ref/Homo_sapiens_assembly38.fasta\")\n",
    "    OUT_SAM = \"/tmp/cnv_realign.\" + str(os.getpid()) + \".sam\"\n",
    "\n",
    "    # DUP development\n",
    "    #IN_CRAM = \"gs://ug-cromwell-tests/structural_variant/030945-NA24385-Z0114-CAACATACATCAGAT.cram\"\n",
    "    IN_CRAM = \"gs://ug-cromwell-tests/cnv/HG002_full_sample/NA24385-Z0027.cram\"\n",
    "    \n",
    "    CNV_BED = os.path.expanduser(\"~/tmp/data/jump_align/251020/dups.bed\")\n",
    "    CNV_BED = os.path.expanduser(\"~/tmp/data/jump_align/251112/dups_small.bed\")\n",
    "\n",
    "    JUMP_ALIGN_CMD = [\"jump_align/\" + JUMP_ALIGN_CMD[0]] + JUMP_ALIGN_CMD[1:]\n",
    "    JUMP_ALIGN_CMD2 = [\"jump_align/\" + JUMP_ALIGN_CMD2[0]] + JUMP_ALIGN_CMD2[1:]\n",
    "\n",
    "    GCLOUD_AUTH = True\n",
    "    INPUT_NAME_FULL = True\n",
    "\n",
    "    MIN_MISMATCHES = 1\n",
    "    FETCH_READ_PADDING = 1500\n",
    "\n",
    "OUT_BED = OUT_SAM.replace(\".sam\", \".bed\")\n",
    "\n",
    "CNV_BED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f2d6c23-4fd3-4f8e-a5fb-e6b8179b4d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCS_OAUTH_TOKEN set to: ya29.a0ATi...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "if GCLOUD_AUTH:\n",
    "\n",
    "    # Run the gcloud command and capture its output\n",
    "    token = subprocess.check_output(\n",
    "        [\"gcloud\", \"auth\", \"print-access-token\"], text=True\n",
    "    ).strip()\n",
    "    \n",
    "    # Set the environment variable for the current process\n",
    "    os.environ[\"GCS_OAUTH_TOKEN\"] = token\n",
    "    \n",
    "    # Optional: print confirmation\n",
    "    print(\"GCS_OAUTH_TOKEN set to:\", token[:10] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad586376-9e10-4978-9a47-0432160f1e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open files\n",
    "import pysam\n",
    "reads_file = pysam.AlignmentFile(IN_CRAM, \"rb\", reference_filename=REF_FASTA)\n",
    "fasta_file = pysam.FastaFile(REF_FASTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e6f5d70-4ee2-41d7-8af7-1e98aa5039d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_process(command, input_path):\n",
    "  command \n",
    "  print(\"command\", \" \".join(command)) \n",
    "    \n",
    "  try:\n",
    "    process = subprocess.Popen(command, \n",
    "                              stdin=subprocess.PIPE, \n",
    "                              stdout=subprocess.PIPE, \n",
    "                              stderr=subprocess.PIPE, \n",
    "                              text=True) \n",
    "\n",
    "    stdout, stderr = process.communicate()\n",
    "    returncode = process.returncode\n",
    "    #print(stderr)\n",
    "\n",
    "  except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error executing command: {e}\")\n",
    "    return None, e.returncode\n",
    "\n",
    "  return stdout, returncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8904d4bc-a80d-4e5f-9356-9889cf619106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def count_md_mismatches(read):\n",
    "    \"\"\"\n",
    "    Count the number of mismatches in a pysam.AlignedSegment read using the MD tag.\n",
    "    Indels are not counted.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        md_tag = read.get_tag(\"MD\")\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "    # Find all letters in the MD string, which represent mismatches\n",
    "    mismatches = re.findall(r\"[A-Z]\", md_tag)\n",
    "    return len(mismatches)\n",
    "\n",
    "def count_nm_mismatches(read):\n",
    "    \"\"\"\n",
    "    Count the number of mismatches in a pysam.AlignedSegment read using the NM tag.\n",
    "    Indels are counted.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nm_tag = read.get_tag(\"NM\")\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "    return int(nm_tag)\n",
    "\n",
    "def count_softclip_mismatches(read, reference):\n",
    "    \"\"\"\n",
    "    Count mismatches in soft-clipped regions (both left and right) of a read.\n",
    "    `read` is a pysam.AlignedSegment\n",
    "    `reference` is a pysam.FastaFile\n",
    "    \"\"\"\n",
    "    if read.is_unmapped:\n",
    "        return 0\n",
    "\n",
    "    seq = read.query_sequence\n",
    "    mismatches = 0\n",
    "    ref_name = read.reference_name\n",
    "    start = read.reference_start\n",
    "    end = read.reference_end\n",
    "\n",
    "    cigartuples = read.cigartuples\n",
    "    # CIGAR operations\n",
    "    SOFT_CLIP = 4\n",
    "\n",
    "    # Left soft clip\n",
    "    if cigartuples[0][0] == SOFT_CLIP:\n",
    "        clip_len = cigartuples[0][1]\n",
    "        clipped_bases = seq[:clip_len]\n",
    "        ref_start = max(0, start - clip_len)\n",
    "        ref_bases = reference.fetch(ref_name, ref_start, start)\n",
    "        for rb, qb in zip(ref_bases, clipped_bases):\n",
    "            if rb.upper() != qb.upper():\n",
    "                mismatches += 1\n",
    "\n",
    "    # Right soft clip\n",
    "    if cigartuples[-1][0] == SOFT_CLIP:\n",
    "        clip_len = cigartuples[-1][1]\n",
    "        clipped_bases = seq[-clip_len:]\n",
    "        ref_bases = reference.fetch(ref_name, end, end + clip_len)\n",
    "        for rb, qb in zip(ref_bases, clipped_bases):\n",
    "            if rb.upper() != qb.upper():\n",
    "                mismatches += 1\n",
    "\n",
    "    return mismatches\n",
    "\n",
    "md_values = []\n",
    "nm_values = []\n",
    "sc_values = []\n",
    "\n",
    "def accept_read(read):\n",
    "    if MIN_MISMATCHES <= 0:\n",
    "        return True\n",
    "    sc = count_softclip_mismatches(read, fasta_file);\n",
    "    nm = count_nm_mismatches(read)\n",
    "    return (sc + nm) >= MIN_MISMATCHES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9499a6cc-6b0d-45a4-82ca-7ff9c03b89a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "# is read soft clipped\n",
    "def is_softclipped(read):\n",
    "    return read.cigartuples[0][0] == pysam.CSOFT_CLIP or read.cigartuples[-1][0] == pysam.CSOFT_CLIP\n",
    "\n",
    "def is_substential_softclipped(read):\n",
    "    return (read.cigartuples[0][0] == pysam.CSOFT_CLIP and read.cigartuples[0][1]) >= SOFTCLIP_THRESHOLD \\\n",
    "                or (read.cigartuples[-1][0] == pysam.CSOFT_CLIP and read.cigartuples[-1][1] >= SOFTCLIP_THRESHOLD)\n",
    "\n",
    "# process a single cnv\n",
    "def process_cnv(chrom, start, end, mode):\n",
    "\n",
    "    # get all reads that cross the two cnv edges\n",
    "    reads = dict()\n",
    "    reads_in_ref = [set(), set()]\n",
    "    refs = []\n",
    "    refs_extents = []\n",
    "    ref_id = 0\n",
    "    for loc in [start, end]:\n",
    "        rmin = max(0, loc - FETCH_READ_PADDING)\n",
    "        rmax = loc + FETCH_READ_PADDING\n",
    "        for read in reads_file.fetch(chrom, max(0, loc - FETCH_READ_PADDING), loc + FETCH_READ_PADDING):\n",
    "            if mode == \"DUP\" and (not is_substential_softclipped(read) and not accept_read(read)) :\n",
    "                continue\n",
    "            #if mode == \"DUP\" and read.is_supplementary:\n",
    "            #    continue\n",
    "            reads[read.qname] = read\n",
    "            rmin = min(rmin, read.reference_start)\n",
    "            rmax = max(rmax, read.reference_end)\n",
    "            reads_in_ref[ref_id].add(read.qname)\n",
    "        refs_extents.append([rmin, rmax])\n",
    "        ref_id += 1\n",
    "        \n",
    "    # extend references before and after\n",
    "    refs_extents[0][0] = max(0, refs_extents[0][0] - FETCH_REF_PADDING)\n",
    "    refs_extents[1][1] = refs_extents[1][1] + FETCH_REF_PADDING\n",
    "\n",
    "    # get references\n",
    "    for extents in refs_extents:\n",
    "        rmin, rmax = extents\n",
    "        ref = fasta_file.fetch(chrom, rmin, rmax)\n",
    "        refs.append([rmin, ref])\n",
    "\n",
    "    # create input file for jump aligner\n",
    "    ref_emitted = False\n",
    "    reads_in_order = []\n",
    "    subsample_ratio = 1.0\n",
    "    if len(reads) > MAX_READS_PER_CNV:\n",
    "        subsample_ratio = MAX_READS_PER_CNV / len(reads)\n",
    "        print(\"subsample_ratio\", subsample_ratio)\n",
    "    nlines = 0\n",
    "    jalign_input = tmp\n",
    "    if INPUT_NAME_FULL:\n",
    "        jalign_input += \"_\" + chrom + \":\" + str(start) + \"-\" + str(end)\n",
    "    with open(jalign_input, 'w') as f:\n",
    "        for read in reads.values():\n",
    "            if subsample_ratio < 1.0:\n",
    "                if random.random() > subsample_ratio:\n",
    "                    continue\n",
    "            if not accept_read(read):\n",
    "                continue\n",
    "            reads_in_order.append(read)\n",
    "            if not ref_emitted:\n",
    "                line = read.qname + \"\\t\" + read.seq + \"\\t\" + refs[1][1] + \"\\t\" + refs[0][1] + \"\\n\"\n",
    "                ref_emitted = True\n",
    "            else:\n",
    "                line = read.qname + \"\\t\" + read.seq + \"\\t=\\n\"\n",
    "            f.write(line)\n",
    "            nlines += 1\n",
    "\n",
    "    # run jump_align\n",
    "    JUMP_ALIGN_CMD[-1] = jalign_input\n",
    "    alignments = run_process(JUMP_ALIGN_CMD, jalign_input)\n",
    "    header_seen = False\n",
    "    realignments = []\n",
    "    rheader = []\n",
    "    for alignment, read in zip(alignments[0].split(\"\\n\"), [None, *reads_in_order]):\n",
    "        if not header_seen:\n",
    "            rheader = alignment.split(\"\\t\")\n",
    "            header_seen = True;\n",
    "        else:\n",
    "            a = alignment.split(\"\\t\")\n",
    "            in1 = read.qname in reads_in_ref[0]\n",
    "            in2 = read.qname in reads_in_ref[1]\n",
    "            realignments.append([read, refs[0][0], refs[1][0], a, in1, in2])\n",
    "    return (rheader, realignments, nlines)\n",
    "\n",
    "# process a single cnv\n",
    "def process_cnv2(chrom, start, end, mode):\n",
    "\n",
    "    # get all reads that cross the two cnv edges\n",
    "    reads = dict()\n",
    "    reads_in_ref = [set(), set()]\n",
    "    refs = []\n",
    "    refs_extents = []\n",
    "    ref_id = 0\n",
    "    for loc in [start, end]:\n",
    "        rmin = max(0, loc - FETCH_READ_PADDING)\n",
    "        rmax = loc + FETCH_READ_PADDING\n",
    "        # print(\"fetching ... \", max(0, loc - FETCH_READ_PADDING), loc + FETCH_READ_PADDING)\n",
    "        for read in reads_file.fetch(chrom, max(0, loc - FETCH_READ_PADDING), loc + FETCH_READ_PADDING):\n",
    "            if mode == \"DUP\" and (not is_substential_softclipped(read) and not accept_read(read)) :\n",
    "                continue\n",
    "            #if mode == \"DUP\" and read.is_supplementary:\n",
    "            #    continue\n",
    "            reads[read.qname] = read\n",
    "            rmin = min(rmin, read.reference_start)\n",
    "            rmax = max(rmax, read.reference_end)\n",
    "            reads_in_ref[ref_id].add(read.qname)\n",
    "        refs_extents.append([rmin, rmax])\n",
    "        ref_id += 1\n",
    "        \n",
    "    # extend references before and after\n",
    "    refs_extents[0][0] = max(0, refs_extents[0][0] - FETCH_REF_PADDING)\n",
    "    refs_extents[1][1] = refs_extents[1][1] + FETCH_REF_PADDING\n",
    "\n",
    "    # get references\n",
    "    for extents in refs_extents:\n",
    "        rmin, rmax = extents\n",
    "        ref = fasta_file.fetch(chrom, rmin, rmax)\n",
    "        refs.append([rmin, ref])\n",
    "\n",
    "    # create input file for jump aligner\n",
    "    ref_emitted = False\n",
    "    reads_in_order = []\n",
    "    subsample_ratio = 1.0\n",
    "    if len(reads) > MAX_READS_PER_CNV:\n",
    "        subsample_ratio = MAX_READS_PER_CNV / len(reads)\n",
    "        print(\"subsample_ratio\", subsample_ratio)\n",
    "    nlines = 0\n",
    "    jalign_input = tmp\n",
    "    if INPUT_NAME_FULL:\n",
    "        jalign_input += \"_\" + chrom + \":\" + str(start) + \"-\" + str(end)\n",
    "    with open(jalign_input, 'w') as f:\n",
    "        for read in reads.values():\n",
    "            if subsample_ratio < 1.0:\n",
    "                if random.random() > subsample_ratio:\n",
    "                    continue\n",
    "            if not accept_read(read):\n",
    "                continue\n",
    "            reads_in_order.append(read)\n",
    "            if not ref_emitted:\n",
    "                line = read.qname + \"\\t\" + read.seq + \"\\t\" + refs[1][1] + \"\\t\" + refs[0][1] + \"\\n\"\n",
    "                ref_emitted = True\n",
    "            else:\n",
    "                line = read.qname + \"\\t\" + read.seq + \"\\t=\\n\"\n",
    "            f.write(line)\n",
    "            nlines += 1\n",
    "\n",
    "    # run jump_align\n",
    "    JUMP_ALIGN_CMD2[-1] = jalign_input\n",
    "    alignments = run_process(JUMP_ALIGN_CMD2, jalign_input)\n",
    "    header_seen = False\n",
    "    realignments = []\n",
    "    rheader = []\n",
    "    for alignment, read in zip(alignments[0].split(\"\\n\"), [None, *reads_in_order]):\n",
    "        if not header_seen:\n",
    "            rheader = alignment.split(\"\\t\")\n",
    "            header_seen = True;\n",
    "        else:\n",
    "            a = alignment.split(\"\\t\")\n",
    "            in1 = read.qname in reads_in_ref[0]\n",
    "            in2 = read.qname in reads_in_ref[1]\n",
    "            realignments.append([read, refs[0][0], refs[1][0], a, in1, in2])\n",
    "    return (rheader, realignments, nlines)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06cfec8e-78fa-41f6-9686-47d19a3ff551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command jump_align/para_jalign 2 -8 -18 -1 -1 0 /tmp/jump_align_input.6038_chr2:122528001-122536001\n",
      "chr2\t122528001\t122536001\tTP\t17\n",
      "\n",
      "command jump_align/para_jalign 2 -8 -18 -1 -1 0 /tmp/jump_align_input.6038_chr2:122526664-122537009\n",
      "chr2\t122526664\t122537009\tTP\t17\n",
      "\n",
      "nlines_total 1525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/cnv_realign.6038.bed'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "chrom_sizes = dict(zip(fasta_file.references, fasta_file.lengths))\n",
    "\n",
    "# loop on bed file, write output bed file\n",
    "nlines_total = 0\n",
    "with open(OUT_BED, \"w\") as out_bed:\n",
    "    with open(CNV_BED) as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            bed_line = line.strip().split()\n",
    "            bed_chrom, bed_start, bed_end = bed_line[:3]\n",
    "            bed_start = int(bed_start)\n",
    "            bed_end = int(bed_end)\n",
    "            #check for valid cnv\n",
    "            if bed_end + FETCH_READ_PADDING > chrom_sizes[bed_chrom]:\n",
    "                continue\n",
    "            '''                \n",
    "            rheader, realignments, nlines = process_cnv(bed_chrom, bed_start, bed_end, MODE)\n",
    "            nlines_total += nlines\n",
    "            jump_better = 0\n",
    "\n",
    "            for realignment in realignments:\n",
    "                in_ref = [False, False]\n",
    "                read, ref1_start, ref2_start, ainfo, in_ref[0], in_ref[1] = realignment\n",
    "    \n",
    "                # decode alignment info\n",
    "                qname1, score, jumpInsertSize, jumpRange, \\\n",
    "                    jbegin1, jcigar1, jreadlen1, jreflen1, \\\n",
    "                    jbegin2, jcigar2, jreadlen2, jreflen2, \\\n",
    "                    score1, begin1, cigar1, readlen1, reflen1, \\\n",
    "                    score2, begin2, cigar2, readlen2, reflen2 = ainfo\n",
    "                score = int(score)\n",
    "                score1 = int(score1)\n",
    "                score2 = int(score2)\n",
    "\n",
    "                # jump score better?\n",
    "                better = False\n",
    "                if score > 0 and score > max(score1, score2) + MIN_SEQ_LEN_JUMP_ALIGN_COMPONENT:\n",
    "                    if int(jreadlen1) >= MIN_SEQ_LEN_JUMP_ALIGN_COMPONENT \\\n",
    "                        and int(jreadlen2) >= MIN_SEQ_LEN_JUMP_ALIGN_COMPONENT \\\n",
    "                        and int(jreflen1) >= MIN_SEQ_LEN_JUMP_ALIGN_COMPONENT \\\n",
    "                        and int(jreflen2) >= MIN_SEQ_LEN_JUMP_ALIGN_COMPONENT:\n",
    "                        better = True\n",
    "    \n",
    "                if better:\n",
    "                    jump_better += 1\n",
    "\n",
    "            outline = line[:-1] + (\"\\t%d\\n\" % (jump_better))\n",
    "            out_bed.write(outline)\n",
    "            print(outline)\n",
    "            '''            \n",
    "            rheader, realignments, nlines = process_cnv2(bed_chrom, bed_start, bed_end, MODE)\n",
    "            nlines_total += nlines\n",
    "            jump_better = 0\n",
    "\n",
    "            for realignment in realignments:\n",
    "                in_ref = [False, False]\n",
    "                read, ref1_start, ref2_start, ainfo, in_ref[0], in_ref[1] = realignment\n",
    "    \n",
    "                # decode alignment info\n",
    "                qname1, better, score, score1, score2, jgain, size1, size2 = ainfo              \n",
    "                score = int(score)\n",
    "                score1 = int(score1)\n",
    "                score2 = int(score2)\n",
    "\n",
    "                # jump score better?\n",
    "                better = False\n",
    "                if score > 0 and score > max(score1, score2) + MIN_SEQ_LEN_JUMP_ALIGN_COMPONENT:\n",
    "                    if int(size1) >= MIN_SEQ_LEN_JUMP_ALIGN_COMPONENT \\\n",
    "                        and int(size2) >= MIN_SEQ_LEN_JUMP_ALIGN_COMPONENT:\n",
    "                        better = True\n",
    "    \n",
    "                if better:\n",
    "                    jump_better += 1\n",
    "\n",
    "            outline = line[:-1] + (\"\\t%d\\n\" % (jump_better))\n",
    "            out_bed.write(outline)\n",
    "            print(outline)\n",
    "\n",
    "print(\"nlines_total\", nlines_total)\n",
    "OUT_BED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25ea972f-ac7b-4416-864d-53cf4d91e612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr2\t122528001\t122536001\tTP\t17\n",
      "chr2\t122526664\t122537009\tTP\t17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"cat \" + OUT_BED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c27cd09-4036-424a-a754-4516ba83a63a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abc7580-3e7d-4214-ab0a-eb08644c1b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
